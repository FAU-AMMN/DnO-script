

<!DOCTYPE html>


<html lang="de" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>1.2. Abstiegsverfahren &#8212; Diskretisierung und numerische Optimierung</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"Z": "\\mathbb{Z}", "V": "V", "N": "\\mathbb{N}", "C": "\\mathbb{C}", "Q": "\\mathbb{Q}", "K": "\\mathbb{K}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "R": ["\\mathbb{R}"], "B": ["\\mathcal{B}"], "norm": ["{\\Vert#1\\Vert}", 1], "abs": ["{\\left|#1\\right|}", 1], "coloneqq": ["{:=}"], "eqqcolon": ["{=:}"], "emph": ["\\pmb#1", 1], "tr": "\\operatorname{Spur}", "lin": "\\operatorname{lin}", "dv": "\\mathrm{div}~", "rot": "\\mathrm{rot}~", "Dim": "\\operatorname{dim}", "diag": "\\operatorname{diag}", "Kern": "\\operatorname{Kern}", "Bild": "\\operatorname{Bild}", "Im": "\\operatorname{Im}", "Rang": "\\operatorname{Rang}", "GL": "\\operatorname{GL}", "Eig": "\\operatorname{Eig}", "End": "\\operatorname{End}", "Hau": "\\operatorname{Haupt}", "mymathbb": ["\\boldsymbol{#1}", 1], "idx": "\\mathrm{d}x", "d": "\\mathrm{d}", "i": "\\mathrm{i}", "x": "\\mathbf{x}", "sign": "\\mathrm{sign}", "vec": ["\\mathbf{#1}", 1], "veczwei": ["\\begin{pmatrix} #1 \\\\ #2 \\end{pmatrix}", 2], "M": "\\mathcal{M}", "S": "\\mathbb{S}", "bone": "\\unicode{x1D7D9}", "Re": "\\mathrm{Re}", "Um": "\\operatorname{Um}", "Res": "\\operatorname{Res}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'optimierung/02_NichtlineareOptimierung/02_02_NichtlineareOptimierung';</script>
    <link rel="index" title="Stichwortverzeichnis" href="../../genindex.html" />
    <link rel="search" title="Suche" href="../../search.html" />
    <link rel="next" title="1.3. Verfahren der konjugierten Gradienten" href="03_02_NichtlineareOptimierung.html" />
    <link rel="prev" title="1.1. Mathematische Grundlagen" href="01_02_NichtlineareOptimierung.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="de"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../01_Einleitung.html">
  
  
  
  
  
  
    <p class="title logo__title">Diskretisierung und numerische Optimierung</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../01_Einleitung.html">
                    Einleitung
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="00_02_NichtlineareOptimierung.html">1. Numerische Optimierung</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_02_NichtlineareOptimierung.html">1.1. Mathematische Grundlagen</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.2. Abstiegsverfahren</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_02_NichtlineareOptimierung.html">1.3. Verfahren der konjugierten Gradienten</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_NichtlineareOptimierung2/00_03_NichtlineareOptimierung2.html">1.4. Wahl der Schrittweite</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_NichtlineareOptimierung2/01_03_NichtlineareOptimierung2.html">1.5. Nicht-differenzierbare Optimierung</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ode/04_Anfangswertprobleme/00_04_Anfangswertprobleme.html">2. Numerische Lösungsverfahren für Anfangswertprobleme</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ode/04_Anfangswertprobleme/01_04_Anfangswertprobleme.html">2.1. Theorie für Anfangswertprobleme gewöhnlicher Differentialgleichungen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ode/04_Anfangswertprobleme/02_04_Anfangswertprobleme.html">2.2. Einschrittverfahren für Anfangswertprobleme</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ode/04_Anfangswertprobleme/03_04_Anfangswertprobleme.html">2.3. Mehrschrittverfahren für Anfangswertprobleme</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ode/04_Anfangswertprobleme/04_04_Anfangswertprobleme.html">2.4. Weiterführende Themen</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ode/05_Randwertprobleme/00_05_Randwertprobleme.html">3. Numerische Lösung von Randwertproblemen</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ode/05_Randwertprobleme/01_05_Randwertprobleme.html">3.1. Existenz und Eindeutigkeit von Lösungen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ode/05_Randwertprobleme/02_05_Randwertprobleme.html">3.2. Differenzenverfahren für Randwertprobleme</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">4. Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/FAU-AMMN/MathPhysicsC" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Quell-Repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Laden Sie diese Seite herunter">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/optimierung/02_NichtlineareOptimierung/02_02_NichtlineareOptimierung.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Quelldatei herunterladen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="In PDF drucken"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Vollbildmodus"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Abstiegsverfahren</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Inhalt </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradientenabstiegsverfahren">1.2.1. Gradientenabstiegsverfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#koordinatenabstiegsverfahren">1.2.2. Koordinatenabstiegsverfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastisches-gradientenabstiegsverfahren">1.2.3. Stochastisches Gradientenabstiegsverfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren">1.2.4. Newton Verfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quasi-newton-verfahren">1.2.5. Quasi-Newton Verfahren</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sekantengleichung-und-krummungsbedingung">1.2.5.1. Sekantengleichung und Krümmungsbedingung</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-davidon-fletcher-powell-verfahren">1.2.5.2. Das Davidon-Fletcher-Powell Verfahren</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-broyden-fletcher-goldfarb-shanno-verfahren">1.2.5.3. Das Broyden–Fletcher–Goldfarb–Shanno Verfahren</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="abstiegsverfahren">
<span id="s-abstiegsverfahren"></span><h1><span class="section-number">1.2. </span>Abstiegsverfahren<a class="headerlink" href="#abstiegsverfahren" title="Permalink to this heading">#</a></h1>
<p>Zu Anfang dieser Vorlesung möchten wir eine Klasse von Algorithmen zur
Optimierung von Funktionen besprechen, die einer simplen und
anschaulichen Idee folgen: die sogenannten <em>Abstiegsverfahren</em> oder auch
<em>Liniensuchverfahren</em> (im Englischen: <em>line search methods</em>). Diese
wurden bereits kurz im Zusammenhang mit dem Gauss-Newton Verfahren in
der Vorlesung Einführung in die Numerik in <span id="id1">[<a class="reference internal" href="../../references.html#id3" title="Daniel Tenbrinck and Tim Roith. Vorlesungsskript zur einführung in die numerik (ws 22/23) an der fau erlangen-nürnberg. URL: https://www.math.fau.de/wp-content/uploads/2023/05/tenbrinck_script_numerik.pdf (visited on 2023-05-23).">TR</a>]</span> erwähnt,
jedoch nicht ausführlich diskutiert. Dies wollen wir im Folgenden
nachholen.</p>
<p>Sei im Folgenden <span class="math notranslate nohighlight">\(\Omega \subset \mathbb{R}^n\)</span> ein offenes,
zusammenhängendes Gebiet und sei
<span class="math notranslate nohighlight">\(F \colon \Omega \rightarrow \mathbb{R}\)</span> eine differenzierbare,
reellwertige Zielfunktion. Die allgemeine Idee der Abstiegsverfahren ist
es nun ausgehend von einem aktuellen Punkt <span class="math notranslate nohighlight">\(x_k \in \Omega\)</span> einen
Schritt in eine Richtung <span class="math notranslate nohighlight">\(p_k \in \mathbb{R}^n\)</span> zu machen, so dass der
Funktionswert von <span class="math notranslate nohighlight">\(F\)</span> in dem neuen Punkt <span class="math notranslate nohighlight">\(x_{k+1}\)</span> abnimmt. Das bedeutet
wir versuchen ein <strong>allgemeines Abstiegsverfahren</strong> der Form</p>
<div class="math notranslate nohighlight" id="equation-eq-abstiegsverfahren">
<span class="eqno">(1.3)<a class="headerlink" href="#equation-eq-abstiegsverfahren" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k + \alpha_k p_k, \quad \alpha_k \in \R^+,\]</div>
<p>zu konstruieren, das in jedem Schritt den Funktionswert <span class="math notranslate nohighlight">\(F(x_k)\)</span>
verringert bis keine Verbesserung mehr möglich ist. Die Schrittweite
<span class="math notranslate nohighlight">\(\alpha_k &gt; 0\)</span> in Richtung <span class="math notranslate nohighlight">\(p_k \in \mathbb{R}^n\)</span> wird häufig in jedem
Schritt des Abstiegsverfahrens neu gewählt.</p>
<section id="gradientenabstiegsverfahren">
<span id="ss-gradient-descent"></span><h2><span class="section-number">1.2.1. </span>Gradientenabstiegsverfahren<a class="headerlink" href="#gradientenabstiegsverfahren" title="Permalink to this heading">#</a></h2>
<p>Zuerst beschäftigen wir uns mit dem wohl bekanntesten Abstiegsverfahren,
dem <em>Gradientenabstiegsverfahren</em> (im Englischen: <em>gradient descent
(GD)</em>). Dieses wird wegen seiner Einfachheit für viele numerische
Optimierungsprobleme verwendet.</p>
<p>Da <span class="math notranslate nohighlight">\(F\)</span> differenzierbar ist können wir dessen Gradienten in jedem Punkt
<span class="math notranslate nohighlight">\(x \in \Omega\)</span> betrachten. Wir gehen im Folgenden immer davon aus, dass
wir den Gradienten <span class="math notranslate nohighlight">\(\nabla F\)</span> der Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> analytisch bestimmen
können und eine Auswertung <span class="math notranslate nohighlight">\(\nabla F(x_k)\)</span> für eine Folge von Punkten
<span class="math notranslate nohighlight">\((x_i)_{i\in\N} \subset \Omega\)</span> numerisch durchführbar ist. Wir werden
also nicht versuchen den Gradienten mit Hilfe von <em>finiten
Differenzenverfahren</em> numerisch zu approximieren.</p>
<p>Der Gradient <span class="math notranslate nohighlight">\(\nabla F(x)\)</span> beschreibt bekanntlich eine Richtung des
stärksten Anstiegs der Funktion <span class="math notranslate nohighlight">\(F\)</span> im Punkt <span class="math notranslate nohighlight">\(x\)</span> und dementsprechend
zeigt der negative Gradient <span class="math notranslate nohighlight">\(-\nabla F(x)\)</span> in die Richtung des stärksten
Abstiegs. Das lässt sich auch formal zeigen indem wir uns die
Taylorapproximation erster Ordnung der Funktion <span class="math notranslate nohighlight">\(F\)</span> in allgemeine
Richtung <span class="math notranslate nohighlight">\(p\)</span> mit Schrittweite <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span> für den <span class="math notranslate nohighlight">\(k\)</span>-ten Schritt des
Abstiegsverfahren näher anschauen. Hier gilt nämlich</p>
<div class="math notranslate nohighlight">
\[F(x_k + \alpha p) \ = \ F(x_k) + \alpha \langle \nabla F(x_k), p \rangle + \mathcal{O}( \nabla^2 F(x_k)),\]</div>
<p>wobei <span class="math notranslate nohighlight">\(\nabla^2 F\)</span> die Hesse-Matrix der Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> bezeichnet. Für
kleine Schrittweiten <span class="math notranslate nohighlight">\(\alpha\)</span> wird klar, dass die Änderung der
Funktionswerte von <span class="math notranslate nohighlight">\(F\)</span> im Wesentlichen von der Größe des Terms
<span class="math notranslate nohighlight">\(\langle \nabla F(x_k), p \rangle\)</span> bestimmt wird. Wir können also für
eine maximale Verringerung der Funktion <span class="math notranslate nohighlight">\(F\)</span> nach derjenigen Richtung mit
Einheitslänge suchen, die das folgende Minimierungsproblem löst:</p>
<div class="math notranslate nohighlight" id="equation-eq-optimization-direction">
<span class="eqno">(1.4)<a class="headerlink" href="#equation-eq-optimization-direction" title="Permalink to this equation">#</a></span>\[\min_{p \in \mathbb{R}^n} \langle \nabla F(x_k), p \rangle \quad \text{ mit } \quad ||p|| = 1.\]</div>
<p>Da außerdem gilt</p>
<div class="math notranslate nohighlight" id="equation-eq-optimization-direction-cosine">
<span class="eqno">(1.5)<a class="headerlink" href="#equation-eq-optimization-direction-cosine" title="Permalink to this equation">#</a></span>\[ \langle \nabla F(x_k), p \rangle \ = \ ||\nabla F(x_k)|| \cdot ||p|| \cdot \cos(\theta),\]</div>
<p>wobei <span class="math notranslate nohighlight">\(\theta\)</span> der Winkel zwischen den Vektoren <span class="math notranslate nohighlight">\(\nabla F(x_k)\)</span> und <span class="math notranslate nohighlight">\(p\)</span>
bildet, können wir das Problem <a class="reference internal" href="#equation-eq-optimization-direction">(1.4)</a>
umschreiben zu</p>
<div class="math notranslate nohighlight">
\[\min_{\theta \in [0,2\pi)} ||\nabla F(x_k)|| \cdot \cos(\theta).\]</div>
<p>Der Kosinus nimmt sein Minimum von <span class="math notranslate nohighlight">\(\cos(\theta)=-1\)</span> in <span class="math notranslate nohighlight">\(\theta = \pi\)</span>
an. Eingesetzt in <a class="reference internal" href="#equation-eq-optimization-direction-cosine">(1.5)</a> erhalten wir
damit, dass die optimale Richtung <span class="math notranslate nohighlight">\(p \in \mathbb{R}^n\)</span> folgenden
Zusammenhang erfüllen muss:</p>
<div class="math notranslate nohighlight">
\[\langle p, \frac{\nabla F(x_k)}{||\nabla F(x_k)||}\rangle \ = \ -1.\]</div>
<p>Da die unbekannte Richtung <span class="math notranslate nohighlight">\(p \in \R^n\)</span> aber normiert sein soll, folgt
damit aber auch schon, dass gilt</p>
<div class="math notranslate nohighlight" id="equation-eq-optimal-direction">
<span class="eqno">(1.6)<a class="headerlink" href="#equation-eq-optimal-direction" title="Permalink to this equation">#</a></span>\[p \ = \ -\frac{\nabla F(x_k)}{||\nabla F(x_k)||}.\]</div>
<p>Das bedeutet, dass der Funktionswert von <span class="math notranslate nohighlight">\(F\)</span> am stärksten in Richtung
des negativen Gradienten abnimmt.</p>
<p>Da wir daran interessiert sind die Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> schnellstmöglich zu
minimieren, macht es Sinn in eben dieser Richtung nach einem lokalen
Minimum zu suchen. Aus dieser Idee heraus lässt sich bereits ein sehr
simpler Algorithmus zur Minimierung von <span class="math notranslate nohighlight">\(F\)</span> formulieren. Sei
<span class="math notranslate nohighlight">\(x_0 \in \Omega\)</span> ein beliebiger Startwert. Dann können wir iterativ eine
Folge von Punkten <span class="math notranslate nohighlight">\(x_1,x_2,\ldots\)</span> in <span class="math notranslate nohighlight">\(\Omega\)</span> bestimmen, so dass die
entsprechenden Funktionswerte von <span class="math notranslate nohighlight">\(F\)</span> monoton fallen sollten:</p>
<div class="math notranslate nohighlight" id="equation-eq-gradient-descent-simple">
<span class="eqno">(1.7)<a class="headerlink" href="#equation-eq-gradient-descent-simple" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k - \nabla F(x_k).\]</div>
<p>Intuitiv stoppt man das Iterationsschema
<a class="reference internal" href="#equation-eq-gradient-descent-simple">(1.7)</a> sobald die Folge der Funktionswerte
<span class="math notranslate nohighlight">\(F(x_k)\)</span> nicht mehr kleiner wird. Man sieht leicht ein, dass das simple
Iterationsschema <a class="reference internal" href="#equation-eq-gradient-descent-simple">(1.7)</a> ein Spezialfall des
allgemeinen Abstiegsverfahrens <a class="reference internal" href="#equation-eq-abstiegsverfahren">(1.3)</a> mit einer
festen Schrittweite <span class="math notranslate nohighlight">\(\alpha_k = 1\)</span> und Richtungsvektor
<span class="math notranslate nohighlight">\(p_k = -\nabla F(x_k)\)</span> ist. Diese einfache Methode lässt sich durch
folgenden Algorithmus implementieren.</p>
<div class="proof algorithm admonition" id="alg:gradient_descent_simple">
<p class="admonition-title"><span class="caption-number">Algorithm 1.1 </span> (Simples Gradientenabstiegsverfahren)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>function</strong> <span class="math notranslate nohighlight">\([x^*, F(x^*)]=\)</span><code class="docutils literal notranslate"><span class="pre">gradientDescentSimple</span></code><span class="math notranslate nohighlight">\((F,\nabla F, x_0)\)</span></p>
<p># Initialisierung<br />
<span class="math notranslate nohighlight">\(x_k = x_0\)</span><br />
<span class="math notranslate nohighlight">\(F(x_{k+1}) = -\infty\)</span></p>
<p><strong>while</strong> <span class="math notranslate nohighlight">\(F(x_{k+1})-F(x_k) &lt; 0\)</span> <strong>do</strong><br />
    # Update in Richtung des größten Gradientenabstiegs<br />
    <span class="math notranslate nohighlight">\(x_{k+1} = x_k - \nabla F(x_k)\)</span><br />
<strong>end while</strong></p>
<p># Ausgabe des letzten Punktes<br />
<span class="math notranslate nohighlight">\(x^* = x_k\)</span><br />
<span class="math notranslate nohighlight">\(F(x^*) = F(x_k)\)</span></p>
</section>
</div><p>Unglücklicherweise ist Algorithmus
<a class="reference internal" href="#alg:gradient_descent_simple">Algorithm 1.1</a> in dieser Form praktisch nicht
anwendbar. Warum dies so ist sieht man leicht an folgendem Beispiel.</p>
<div class="proof example admonition" id="ex:gradient_descent_simple">
<p class="admonition-title"><span class="caption-number">Example 1.2 </span> (Simpler Gradientenabstieg)</p>
<section class="example-content" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(\Omega = \mathbb{R}\)</span> und sei <span class="math notranslate nohighlight">\(F(x) \coloneqq |x|\)</span>. Man beachte,
dass <span class="math notranslate nohighlight">\(F\)</span> überall differenzierbar ist, außer an der Stelle <span class="math notranslate nohighlight">\(x=0\)</span>. Das
eindeutig bestimmte, globale Minimum der konvexen, nichtlinearen
Funktion <span class="math notranslate nohighlight">\(F\)</span> wird ebenfalls in <span class="math notranslate nohighlight">\(x^* = 0\)</span> angenommen.</p>
<p>Definiert man <span class="math notranslate nohighlight">\(\nabla F(0) \coloneqq 0\)</span> in der Singularität, so erhält
man das Minimum <span class="math notranslate nohighlight">\(x^* = 0\)</span> durch Algorithmus
<a class="reference internal" href="#alg:gradient_descent_simple">Algorithm 1.1</a> nur für Startwerte
<span class="math notranslate nohighlight">\(x_0 \in \mathbb{Z}\)</span>. Wähle zum Beispiel den Startwert <span class="math notranslate nohighlight">\(x_0 = 0.5\)</span>, so
terminiert das Gradientenabstiegsverfahren bereits nach dem ersten
Schritt ohne eine gute Näherung an <span class="math notranslate nohighlight">\(x^* = 0\)</span> zu liefern.</p>
</section>
</div><p>Wie das <a class="reference internal" href="#ex:gradient_descent_simple">Example 1.2</a> zeigt, besteht bei dem
Gradientenabstiegsverfahren in Algorithmus
<a class="reference internal" href="#alg:gradient_descent_simple">Algorithm 1.1</a> die Gefahr einen stationären
Punkt und somit ein potentielles Minimum zu überspringen. Aus diesem
Grund kommt man auf die Idee die Schrittweite <span class="math notranslate nohighlight">\(\alpha_k &gt; 0\)</span> in
<a class="reference internal" href="#equation-eq-abstiegsverfahren">(1.3)</a> <strong>genügend klein</strong> zu wählen. Damit diese
feste Schrittweite unabhängig von der Magnitude des Gradienten
<span class="math notranslate nohighlight">\(\nabla F\)</span> ist, normiert man in der Regel die Richtung des steilsten
Gradientenabstiegs durch die Norm des Gradienten, d.h., wir erhalten
eine <strong>steuerbare Version des Gradientenabstiegsverfahrens</strong> in
<a class="reference internal" href="#equation-eq-gradient-descent-simple">(1.7)</a> durch:</p>
<div class="math notranslate nohighlight" id="equation-eq-gradient-descent-control">
<span class="eqno">(1.8)<a class="headerlink" href="#equation-eq-gradient-descent-control" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k - \tau \frac{\nabla F(x_k)}{||\nabla F(x_k)||}, \quad \tau &gt; 0 .\]</div>
<p>Das Iterationsschema <a class="reference internal" href="#equation-eq-gradient-descent-adaptive">(1.9)</a> ist wiederum ein
Spezialfall des allgemeinen Abstiegsverfahrens in
<a class="reference internal" href="#equation-eq-abstiegsverfahren">(1.3)</a> für eine feste Schritteweite
<span class="math notranslate nohighlight">\(\alpha_k = \tau &gt; 0\)</span> und den Richtungsvektor
<span class="math notranslate nohighlight">\(p_k = -\nabla F(x_k) / ||\nabla F(x_k)||\)</span>.</p>
<p>Es ist klar, dass durch eine kleinere Schrittweite <span class="math notranslate nohighlight">\(\tau &gt; 0\)</span> ein
stationärer Punkt <span class="math notranslate nohighlight">\(x^* \in \Omega\)</span> der Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> immer besser
angenähert werden kann. Leider erhöht sich aber gleichzeit die benötigte
Iterationszahl zur Erreichung einer erwünschten Genauigkeit
<span class="math notranslate nohighlight">\(|F(x^*) - F(x_k)| &lt; \epsilon\)</span> je kleiner man die Schrittweite <span class="math notranslate nohighlight">\(\tau\)</span>
wählt. Man muss also bei der Wahl der Schrittweite einen Kompromiss
zwischen Genauigkeit der numerischen Approximation und der Laufzeit des
Verfahrens eingehen.</p>
<p>Eine weiterführende Idee ist es die Schrittweiten <strong>adaptiv</strong> zu wählen,
dass heißt man passt sie innerhalb des Iterationsschemas an die
Funktionswerte von <span class="math notranslate nohighlight">\(F\)</span> geeignet an. Ein Iterationsschema, dass eine
immer kleiner werdende Schrittweite <span class="math notranslate nohighlight">\(\alpha_k &gt; 0\)</span> verwendet, lässt sich
für einen fest gewählten Reduktionsfaktor <span class="math notranslate nohighlight">\(0 &lt; \sigma &lt; 1\)</span> wie folgt
angeben:</p>
<div class="math notranslate nohighlight" id="equation-eq-gradient-descent-adaptive">
<span class="eqno">(1.9)<a class="headerlink" href="#equation-eq-gradient-descent-adaptive" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{split}
\alpha_{k+1} \ &amp;= \
\begin{cases}
\ \alpha_k, \quad &amp;\text{ falls } F\left(x_k - \alpha_k \frac{\nabla F(x_k)}{||\nabla F(x_k)||}\right) &lt; F(x_k) , \\
\ \sigma \alpha_k, \quad &amp;\text{ sonst}.
\end{cases},\\
x_{k+1} \ &amp;= \ x_k - \alpha_{k+1} \frac{\nabla F(x_k)}{||\nabla F(x_k)||}.
\end{split}\end{split}\]</div>
<p>Das adaptive Gradientenabstiegsverfahren in
<a class="reference internal" href="#equation-eq-gradient-descent-adaptive">(1.9)</a> lässt sich mit folgendem Algorithmus
umsetzen.</p>
<p>\</p>
<div class="proof algorithm admonition" id="alg:gradient_descent_adaptive">
<p class="admonition-title"><span class="caption-number">Algorithm 1.2 </span> (Adaptives Gradientenabstiegsverfahren)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>function</strong> <span class="math notranslate nohighlight">\([x^*, F(x^*)]=\)</span><code class="docutils literal notranslate"><span class="pre">gradientDescentAdaptive</span></code><span class="math notranslate nohighlight">\((F,\nabla F, x_0, \alpha_0, \sigma, \epsilon\)</span>)</p>
<p># Initialisierung<br />
<span class="math notranslate nohighlight">\(\alpha_k = \alpha_0\)</span><br />
<span class="math notranslate nohighlight">\(x_k = x_0\)</span><br />
<span class="math notranslate nohighlight">\(F(x_{k+1}) = +\infty\)</span></p>
<p># Iteriere bis gewünschte Genauigkeit erreicht ist<br />
<strong>while</strong> <span class="math notranslate nohighlight">\(|F(x_{k+1}) - F(x_k)| &gt; \epsilon\)</span> <strong>do</strong><br />
    <strong>while</strong> <span class="math notranslate nohighlight">\(F(x_k) - \alpha_k \nabla F(x_k)/|| \nabla F(x_k)||) &gt; F(x_k)\)</span> <strong>do</strong><br />
        # Verringere Schrittweite um Faktor <span class="math notranslate nohighlight">\(\sigma\)</span><br />
        <span class="math notranslate nohighlight">\(\alpha_k = \sigma\alpha_k\)</span><br />
    <strong>end while</strong><br />
    # Update in Richtung des größten Gradientenabstiegs<br />
    <span class="math notranslate nohighlight">\(x_{k+1} = x_k - \alpha_k\nabla F(x_k)/||\nabla F(x_k)||\)</span><br />
<strong>end while</strong></p>
<p># Ausgabe des letzten Punktes<br />
<span class="math notranslate nohighlight">\(x^* = x_k\)</span><br />
<span class="math notranslate nohighlight">\(F(x^*) = F(x_k)\)</span></p>
</section>
</div><div class="proof remark admonition" id="remark-3">
<p class="admonition-title"><span class="caption-number">Remark 1.5 </span> (Zurücksetzen der Schrittweite)</p>
<section class="remark-content" id="proof-content">
<p>In manchen Anwendungsfällen macht es Sinn die Schrittweite
<span class="math notranslate nohighlight">\(\alpha_{k+1}\)</span> in <a class="reference internal" href="#equation-eq-gradient-descent-adaptive">(1.9)</a> in jedem Schritt
wieder auf den initialen Wert <span class="math notranslate nohighlight">\(\alpha_0 &gt; 0\)</span> zurückzusetzen, um eine
verbesserte Konvergenzgeschwindigkeit zu erhalten. Dies macht vor allem
dann SInn, wenn eine Auswertung der Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> und ihres
Gradienten <span class="math notranslate nohighlight">\(\nabla F\)</span> numerisch günstig zu realisieren ist.</p>
</section>
</div><figure class="align-default" id="fig-gradient-descent-adaptive">
<img alt="../../_images/gradient_descent.png" src="../../_images/gradient_descent.png" />
<figcaption>
<p><span class="caption-number">Abb. 1.1 </span><span class="caption-text">Approximation des Minimierers einer Funktion <span class="math notranslate nohighlight">\(F\)</span> in zwei Variablen mit
Hilfe des adaptiven Gradientenverfahrens
<a class="reference internal" href="#equation-eq-gradient-descent-adaptive">(1.9)</a>.</span><a class="headerlink" href="#fig-gradient-descent-adaptive" title="Link zu diesem Bild">#</a></p>
</figcaption>
</figure>
<p>In <a class="reference internal" href="#fig-gradient-descent-adaptive"><span class="std std-numref">Abb. 1.1</span></a> ist ein typischer Verlauf des
adaptiven Gradientenverfahrens in Algorithmus
<a class="reference internal" href="#alg:gradient_descent_adaptive">Algorithm 1.2</a> bei der Minimierung einer
konvexen Zielfunktion <span class="math notranslate nohighlight">\(F \colon \mathbb{R}^2 \rightarrow \mathbb{R}\)</span> zu
sehen. Man erkennt, dass die Schrittweiten immer kleiner werden, je
näher man sich dem lokalen Minimum <span class="math notranslate nohighlight">\(x_*\)</span> nähert. Außerdem sieht man,
dass die Richtung des steilsten Gradientenabstiegs immer orthogonal zu
den Niveaulinien der zu minimierenden Funktion steht.</p>
<div class="proof remark admonition" id="remark-4">
<p class="admonition-title"><span class="caption-number">Remark 1.6 </span></p>
<section class="remark-content" id="proof-content">
<p>Das in diesem Abschnitt beschriebene Gradientenabstiegsverfahren mit
adaptiver Schrittweite <span class="math notranslate nohighlight">\(\alpha_k &gt; 0\)</span> ist ein gängiger Algorithmus zur
Minimierung einer Funktion <span class="math notranslate nohighlight">\(F\)</span>, wenn deren Ableitung <span class="math notranslate nohighlight">\(\nabla F\)</span> bekannt
und numerisch günstig zu berechnen ist. Dennoch gibt es Situationen in
denen es ratsam ist alternative Optimierungsalgorithmen zu verwenden.
Zum Beispiel ist ein häufiges Problem des Gradientenverfahrens die
starke Verlangsamung in der Nähe eines Sattelpunktes, was zu sehr langen
Laufzeiten des Algorithmus führt. Außerdem passiert die Minimierung
einer Funktion <span class="math notranslate nohighlight">\(F\)</span> mit Hilfe des Gradientenabstiegsverfahrens in der
Regel entlang eines Zickzack-Pfades (siehe
<a class="reference internal" href="#fig-gradient-descent-adaptive"><span class="std std-numref">Abb. 1.1</span></a>), welcher in den meisten Fällen
offensichtlich suboptimal ist. Aus diesen Gründen wollen wir uns in den
nächsten Abschnitten mit alternativen Minimierungsmethoden beschäftigen.</p>
</section>
</div></section>
<section id="koordinatenabstiegsverfahren">
<span id="ss-coordinate-descent"></span><h2><span class="section-number">1.2.2. </span>Koordinatenabstiegsverfahren<a class="headerlink" href="#koordinatenabstiegsverfahren" title="Permalink to this heading">#</a></h2>
<p>Eine weitere Variante des in <a class="reference internal" href="#ss-gradient-descent"><span class="std std-ref">Gradientenabstiegsverfahren</span></a> behandelten
Gradientenabstiegsverfahrens ist das <em>Koordinatenabstiegsverfahren</em> (im
Englischen: <em>coordinate descent</em> (CD)).</p>
<p>Die grundlegende Idee des Koordinatenabstiegsverfahrens ist es in jedem
Schritt des Iterationsschemas eine <em>Koordinatenrichtung</em> auszuwählen und
einen Abstieg in diese Richtung durchzuführen. Damit lässt sich ein
möglicherweise kompliziertes multivariates Optimierungsproblem durch
eine Reihe von einfachen univariaten Optimierungsproblemen behandeln.
Die Auswahl der Koordinatenrichtung kann entweder mit Hilfe einer
Auswahlregel, z.B. mit einem <em>Rundlaufverfahren</em>, oder aber <em>zufällig</em>
geschehen.</p>
<p>Wir wollen im Folgenden den Fall einer <strong>zufälligen Wahl der
Koordinatenrichtung</strong> diskutieren. Für einen zufälligen Index
<span class="math notranslate nohighlight">\(j \in \lbrace 1,\ldots,n\rbrace\)</span> und den entsprechenden zufälligen
Einheitsvektor <span class="math notranslate nohighlight">\(e_j \in \mathbb{R}^n\)</span> lässt sich das
Koordinatenabstiegsverfahren schreiben als:</p>
<div class="math notranslate nohighlight" id="equation-eq-coordinate-descent-stochastic">
<span class="eqno">(1.10)<a class="headerlink" href="#equation-eq-coordinate-descent-stochastic" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k - \alpha_k \langle \nabla F(x_k), e_j \rangle e_j \ = \ x_k - \alpha_k \frac{\partial F}{\partial x^i}(x_k) e_j.\]</div>
<p>Das bedeutet, dass man in jeder Iteration nur eine Koordinate des
aktuellen Parametervektors <span class="math notranslate nohighlight">\(x_k \in \Omega\)</span> verändern muss. Die
Schrittweite <span class="math notranslate nohighlight">\(\alpha_k &gt; 0\)</span> in <a class="reference internal" href="#equation-eq-coordinate-descent-stochastic">(1.10)</a>
kann hierbei ähnlich wie in <a class="reference internal" href="#ss-gradient-descent"><span class="std std-ref">Gradientenabstiegsverfahren</span></a> <em>fest</em> oder
<em>adaptiv</em> gewählt werden. Das Koordinatenabstiegsverfahren in
<a class="reference internal" href="#equation-eq-coordinate-descent-stochastic">(1.10)</a> mit adaptiver Schrittweite lässt
sich mit folgendem Algorithmus umsetzen.</p>
<p>\</p>
<div class="proof algorithm admonition" id="algorithm-5">
<p class="admonition-title"><span class="caption-number">Algorithm 1.3 </span> (Koordinatenabstiegsverfahren)</p>
<section class="algorithm-content" id="proof-content">
<p>label=“alg:coordinate_descent_stochastic“}</p>
<p><strong>function</strong> <span class="math notranslate nohighlight">\([x^*, F(x^*)]=\)</span><code class="docutils literal notranslate"><span class="pre">coordinateDescentStochastic</span></code><span class="math notranslate nohighlight">\((F,\nabla F, x_0, \alpha_0, \sigma, \epsilon\)</span>)</p>
<p># Initialisierung<br />
<span class="math notranslate nohighlight">\(\alpha_k = \alpha_0\)</span><br />
<span class="math notranslate nohighlight">\(x_k = x_0\)</span><br />
<span class="math notranslate nohighlight">\(F(x_{k+1}) = +\infty\)</span></p>
<p># Iteriere bis gewünschte Genauigkeit erreicht ist<br />
<strong>while</strong> <span class="math notranslate nohighlight">\(|F(x_{k+1} - F(x_k)|&gt;\epsilon\)</span> <strong>do</strong><br />
<br />
    # Wähle zufällige Koordinatenrichtung<br />
    <span class="math notranslate nohighlight">\(i = \texttt{randomDraw}([1:n])\)</span><br />
<br />
    # Berechne Ableitung in Koordinatenrichtung<br />
    <span class="math notranslate nohighlight">\(p_k = \frac{\partial}{\partial x_k^i}F(x_k) \cdot e_i\)</span><br />
<br />
    <strong>while</strong> <span class="math notranslate nohighlight">\(F(x_k - \alpha_k p_k) &gt; F(x_k)\)</span> <strong>do</strong><br />
        # Verringere Schrittweite um Faktor <span class="math notranslate nohighlight">\(\sigma\)</span><br />
        <span class="math notranslate nohighlight">\(\alpha_k = \sigma\alpha_k\)</span><br />
    <strong>end while</strong><br />
<br />
    # Update in Richtung des größten Gradientenabstiegs<br />
    <span class="math notranslate nohighlight">\(x_{k+1} = x_k - \alpha_k p_k\)</span><br />
<strong>end while</strong><br />
<br />
# Ausgabe des letzten Punktes<br />
<span class="math notranslate nohighlight">\(x^* = x_k\)</span><br />
<span class="math notranslate nohighlight">\(F(x^*) = F(x_k)\)</span></p>
</section>
</div><p>Das Koordinatenabstiegsverfahren benötigt in der Regel deutlich mehr
Iterationen als das normale Gradientenabstiegsverfahren und beschreibt
häufig noch mehr einen Zickzack-Pfad bei der Minimierung. Dennoch bietet
das Verfahren Vorteile gegenüber dem Gradientenabstiegsverfahren gerade
in Optimierungsproblemen mit vielen Variablen (z.B. für das Training
eines künstlichen neuronalen Netzes), da jedes eindimensionale
Optimierungsproblem wesentlich leichter zu lösen ist als die Berechnung
des gesamten Gradienten in jedem Schritt.</p>
<div class="proof remark admonition" id="remark-6">
<p class="admonition-title"><span class="caption-number">Remark 1.7 </span> (Blockkoordinatenabstiegsverfahren)</p>
<section class="remark-content" id="proof-content">
<p>Um den Zufallseffekten und den damit verbundenen Zickzack Pfad bei der
Minimierung der Funktion <span class="math notranslate nohighlight">\(F\)</span> durch das Koordinatenabstiegsverfahren
entgegen zu wirken, kann man einen Kompromiss zwischen der Verwendung
einer einzelnen Koordinatenrichtung und dem gesamten Gradienten
eingehen. Hierbei spricht man von den sogenannten
<em>Blockkoordinatenabtiegsverfahren</em> (im Englischen <em>block coordinate
descent</em> (BCD)). Hierbei wählt man zuerst die Größe
<span class="math notranslate nohighlight">\(s \in \lbrace 1,\ldots,n\rbrace\)</span> der Koordinatenblöcke, d.h., die Größe
der Teilmenge der verwendeten Richtungsableitungen des Gradienten
<span class="math notranslate nohighlight">\(\nabla F\)</span>. Anschließend wird in jedem Schritt ein Block an
Koordinatenrichtungen deterministisch oder zufällig ausgewählt und in
dessen Richtung minimiert. Für eine zufällige Wahl der Koordinatenblöcke
ergibt sich somit:</p>
<div class="math notranslate nohighlight" id="equation-eq-block-coordinate-descent">
<span class="eqno">(1.11)<a class="headerlink" href="#equation-eq-block-coordinate-descent" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k - \alpha_k \sum_{i=1}^s \langle \nabla F(x_k), e_{\sigma(i)} \rangle e_{\sigma(i)}.\]</div>
<p>Hierbei ist
<span class="math notranslate nohighlight">\(\sigma \colon \lbrace1,\ldots,n\rbrace \rightarrow \ \lbrace1,\ldots,n\rbrace\)</span>
eine zufällige Permutation der Indizes <span class="math notranslate nohighlight">\(1,\ldots,n\)</span>. Es ist klar, dass
das Koordinatenabstiegsverfahren in
<a class="reference internal" href="#equation-eq-coordinate-descent-stochastic">(1.10)</a> und das normale
Gradientenabstiegsverfahren in <a class="reference internal" href="#equation-eq-gradient-descent-adaptive">(1.9)</a>
Spezialfälle des Blockkoordinatenabstiegsverfahrens in
<a class="reference internal" href="#equation-eq-block-coordinate-descent">(1.11)</a> für Blockgrößen <span class="math notranslate nohighlight">\(s = 1\)</span> und <span class="math notranslate nohighlight">\(s=n\)</span>
sind.</p>
</section>
</div></section>
<section id="stochastisches-gradientenabstiegsverfahren">
<span id="ss-stochastic-gradient-descent"></span><h2><span class="section-number">1.2.3. </span>Stochastisches Gradientenabstiegsverfahren<a class="headerlink" href="#stochastisches-gradientenabstiegsverfahren" title="Permalink to this heading">#</a></h2>
<p>Eine aktuell weit verbreitete Variante des Gradientenabstiegsverfahrens
in <a class="reference internal" href="#equation-eq-gradient-descent-adaptive">(1.9)</a> ist das <em>stochastische
Gradientenabstiegsverfahren</em> (im Englischen: <em>stochastic gradient
descent</em> (SGD)). Wie der Name schon verrät handelt es sich hierbei nicht
um einen deterministischen Algorithmus. Das bedeutet, dass man bei
mehrmaliger Anwendung des Verfahrens bei gleichbleibenden
Startbedingungen in der Regel unterschiedliche Ergebnisse in
unterschiedlichen Laufzeiten erhält. Was auf den ersten Blick wie ein
Nachteil wirkt, kann in manchen Fällen jedoch praktische Eigenschaften
mit sich bringen. So kann die Zufallsnatur des stochastischen
Gradientenverfahrens dazu führen, dass Sattelpunkte und ungewollte,
lokale Minima der Funktion durch die Folge der Punkte vermieden werden.
Das Verfahren findet aktuell vor allem beim Training von neuronalen
Netzen bei der sogenannten <em>Backpropagation</em> in verschiedenen
Variationen Anwendung, da man hierdurch dem bekannten Problem des
<em>Übertrainierens</em> des neuronalen Netzes entgegen wirken kann.</p>
<p>Beim stochastischen Gradientenverfahren geht man davon aus, dass sich
die zu minimierende Zielfunktion
<span class="math notranslate nohighlight">\(F \colon \Omega \rightarrow \mathbb{R}\)</span> als eine Summe der folgenden
Gestalt schreiben lässt:</p>
<div class="math notranslate nohighlight" id="equation-eq-objective-function-sum">
<span class="eqno">(1.12)<a class="headerlink" href="#equation-eq-objective-function-sum" title="Permalink to this equation">#</a></span>\[F(x) \ = \ \sum_{i=1}^m F_i(x), \quad \text{ für alle } x \in \Omega.\]</div>
<p>Solche Zielfunktionen treten natürlicherweise in vielen
Problemstellungen auf, zum Beispiel bei Maximimum-Likelihood Ansätzen
oder der Methode der kleinsten Quadrate. Im Bereich des maschinellen
Lernens lässt sich der Trainingsfehler über alle Trainingsdaten in der
Regel als eine solche Summe schreiben. In diesem Fall lässt sich das
normale Gradientenabstiegsverfahren in
<a class="reference internal" href="#equation-eq-gradient-descent-adaptive">(1.9)</a> umschreiben zu:</p>
<div class="math notranslate nohighlight" id="equation-eq-gradient-descent-sum">
<span class="eqno">(1.13)<a class="headerlink" href="#equation-eq-gradient-descent-sum" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k - \alpha_k \frac{\nabla F(x_k)}{||\nabla F(x_k)||} \ = \ x_k - \alpha_k \frac{\sum_{i=1}^m\nabla F_i(x_k)}{||\sum_{i=1}^m\nabla F_i(x_k)||}, \quad \alpha_k &gt; 0 .\]</div>
<p>Die Idee des stochastischen Gradientenverfahrens ist es nun einen
zufälligen Summanden aus <a class="reference internal" href="#equation-eq-objective-function-sum">(1.12)</a> zu wählen und
nur den Gradienten bezüglich dieses Summanden zu betrachten. Durch diese
starke Vereinfachung von <a class="reference internal" href="#equation-eq-gradient-descent-sum">(1.13)</a> führt man mit
einem zufällig ausgewählten Index <span class="math notranslate nohighlight">\(j \in \lbrace 1,\ldots,m\rbrace\)</span> nun
einen Gradientenabstieg der Form</p>
<div class="math notranslate nohighlight" id="equation-eq-stochastic-gradient-descent">
<span class="eqno">(1.14)<a class="headerlink" href="#equation-eq-stochastic-gradient-descent" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k - \alpha_k \frac{\nabla F_j(x_k)}{||\nabla F_j(x_k)||}, \quad \alpha_k &gt; 0\]</div>
<p>durch.</p>
<div class="proof remark admonition" id="remark-7">
<p class="admonition-title"><span class="caption-number">Remark 1.8 </span></p>
<section class="remark-content" id="proof-content">
<p>Ähnlich wie im Fall des Koordinatenabstiegsverfahrens in Kapitel
<a class="reference internal" href="#ss-coordinate-descent"><span class="std std-ref">Koordinatenabstiegsverfahren</span></a>, gibt es auch beim stochastischen
Gradientenverfahren die Möglichkeit einen Kompromiss zwischen dem
normalen Gradientenabstieg in <a class="reference internal" href="#equation-eq-gradient-descent-control">(1.8)</a> und dem
auf einen Summanden beschränkten Gradientenabstieg
<a class="reference internal" href="#equation-eq-stochastic-gradient-descent">(1.14)</a> einzugehen. Indem man eine
zufällige Untermenge von fester Größe <span class="math notranslate nohighlight">\(s \in \lbrace 1,\ldots,m\rbrace\)</span>
von Summanden von <span class="math notranslate nohighlight">\(F\)</span> auswählt, lässt sich das sogenannte <em>stochastische
Minibatch-Gradientenabstiegsverfahren</em> formulieren:</p>
<div class="math notranslate nohighlight">
\[x_{k+1} = x_k - \alpha_k \frac{\sum_{i=1}^s\nabla F_{\sigma(i)}(x_k)}{||\sum_{i=1}^s\nabla F_{\sigma(i)}(x_k)||}, \quad \alpha_k &gt; 0 .\]</div>
<p>Hierbei ist
<span class="math notranslate nohighlight">\(\sigma \colon \lbrace 1,\ldots,m\rbrace \rightarrow \lbrace 1,\ldots,m\rbrace\)</span>
eine zufällige Permutation der Indizes <span class="math notranslate nohighlight">\(1,\ldots,m\)</span>.</p>
</section>
</div></section>
<section id="newton-verfahren">
<span id="ss-newton"></span><h2><span class="section-number">1.2.4. </span>Newton Verfahren<a class="headerlink" href="#newton-verfahren" title="Permalink to this heading">#</a></h2>
<p>In diesem Abschnitt wollen wir uns das bereits bekannte Newton-Verfahren
in Erinnerung rufen und dieses geeignet zur Optimierung von
nichtlinearen Funktionen verallgemeinern. In <span id="id2">[<a class="reference internal" href="../../references.html#id3" title="Daniel Tenbrinck and Tim Roith. Vorlesungsskript zur einführung in die numerik (ws 22/23) an der fau erlangen-nürnberg. URL: https://www.math.fau.de/wp-content/uploads/2023/05/tenbrinck_script_numerik.pdf (visited on 2023-05-23).">TR</a>]</span> haben
wir das <em>Newton Verfahren</em> zur Approximation von Nullstellen
nichtlinearer Gleichungssysteme hergeleitet. Wir haben zunächst die
Taylorapproximation einer nichtlinearen Nullstellengleichung
<span class="math notranslate nohighlight">\(F(x^*) = 0\)</span> von der folgenden Form betrachtet</p>
<div class="math notranslate nohighlight">
\[0 \ = \ F(x^*) \ \approx \ F(x) + F'(x)(x^* - x),\]</div>
<p>wobei <span class="math notranslate nohighlight">\(F'\)</span> die als regulär angenommene Jacobi-Matrix der
differenzierbaren Funktion <span class="math notranslate nohighlight">\(F \colon \R^n \rightarrow \R^n\)</span> bezeichnet.
Hierauf basierend haben wir die folgende <strong>Fixpunktfunktion</strong> als
Approximation erster Ordnung angegeben:</p>
<div class="math notranslate nohighlight" id="equation-eq-newton-fixpunkt">
<span class="eqno">(1.15)<a class="headerlink" href="#equation-eq-newton-fixpunkt" title="Permalink to this equation">#</a></span>\[G(x) \ = \ x - (F'(x))^{-1} F(x), \quad \text{ für } F'(x) \text{ regulär}.\]</div>
<p>Hierbei haben wir die Fixpunktgleichung als erfüllt gesehen, wenn wir
ein <span class="math notranslate nohighlight">\(x^* \in \Omega\)</span> gefunden haben, so dass für die Fixpunktgleichung
<a class="reference internal" href="#equation-eq-newton-fixpunkt">(1.15)</a> gilt <span class="math notranslate nohighlight">\(x^* = G(x^*)\)</span>. Unter dieser Beobachtung
haben wir das <em>Newton-Verfahren</em> als iteratives Schema zur Bestimmung
eines solchen Fixpunktes <span class="math notranslate nohighlight">\(x^* \in \Omega\)</span> hergeleitet:</p>
<div class="math notranslate nohighlight">
\[x_{k+1} \ = \ x_k - (F'(x_k))^{-1} F(x_k),, \quad \text{ für } F'(x_k) \text{ regulär}.\]</div>
<p>Hierfür benötigten wir einen geeigneten Startwert <span class="math notranslate nohighlight">\(x_0 \in \Omega\)</span> in
einer lokalen Umgebung <span class="math notranslate nohighlight">\(U \subset \Omega\)</span> des Fixpunktes <span class="math notranslate nohighlight">\(x^* \in U\)</span>.</p>
<p>Der folgende Satz formuliert Bedingungen für die lokale Konvergenz des
Newton-Verfahrens.</p>
<div class="proof theorem admonition" id="theorem-8">
<p class="admonition-title"><span class="caption-number">Theorem 1.4 </span> (Lokale Konvergenz des Newton Verfahrens)</p>
<section class="theorem-content" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(F: \R^n \rightarrow \R^n\)</span> in einer Umgebung von
<span class="math notranslate nohighlight">\(\overline{x} \in \R^n\)</span> stetig differenzierbar und <span class="math notranslate nohighlight">\(\overline{x}\)</span> sei
eine Nullstelle von <span class="math notranslate nohighlight">\(F\)</span> mit <span class="math notranslate nohighlight">\(F(\overline{x}) = 0\)</span>. Sei außerdem die
Jacobi-Matrix <span class="math notranslate nohighlight">\(F'\)</span> lokal Lipschitz-stetig und <span class="math notranslate nohighlight">\(F'(\overline{x})\)</span> regulär
in der Nullstelle.</p>
<p>Dann existiert eine lokale Umgebung <span class="math notranslate nohighlight">\(B_R(\overline{x})\)</span>, so dass das
Newton-Verfahren für jeden Startwert <span class="math notranslate nohighlight">\(x_0 \in B_R(\overline{x})\)</span> gegen
die Nullstelle <span class="math notranslate nohighlight">\(\overline{x}\)</span> konvergiert, d.h. es gilt
<span class="math notranslate nohighlight">\(\lim_{x\rightarrow \infty} x_k =  \overline{x}\)</span>.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. Siehe <span id="id3">[<a class="reference internal" href="../../references.html#id3" title="Daniel Tenbrinck and Tim Roith. Vorlesungsskript zur einführung in die numerik (ws 22/23) an der fau erlangen-nürnberg. URL: https://www.math.fau.de/wp-content/uploads/2023/05/tenbrinck_script_numerik.pdf (visited on 2023-05-23).">TR</a>]</span>. ◻</p>
</div>
<p>Anstatt nun eine Nullstelle der Funktion <span class="math notranslate nohighlight">\(F\)</span> zu suchen, wollen wir das
Newton-Verfahren nutzen, um eine Nullstelle des Gradienten <span class="math notranslate nohighlight">\(\nabla F\)</span>
(d.h einen stationären Punkt von <span class="math notranslate nohighlight">\(F\)</span>) zu approximieren und damit die
notwendigen Optimalitätsbedingungen in <a class="reference internal" href="01_02_NichtlineareOptimierung.html#thm:minimum_notwendig">Theorem 1.1</a>
zu erfüllen. Im Folgenden sei <span class="math notranslate nohighlight">\(\Omega \subset \mathbb{R}^n\)</span> ein offenes,
zusammenhängendes Gebiet und <span class="math notranslate nohighlight">\(F \colon \Omega \rightarrow \mathbb{R}\)</span>
eine differenzierbare, reellwertige Funktion. Wir betrachten wieder die
Taylorapproximation der Funktion <span class="math notranslate nohighlight">\(F\)</span> in eine Abstiegsrichtung
<span class="math notranslate nohighlight">\(x_k + p \in \Omega\)</span> des allgemeinen Iterationsschemas
<a class="reference internal" href="#equation-eq-abstiegsverfahren">(1.3)</a>, aber berücksichtigen diesmal auch Terme von
zweiter Ordnung:</p>
<div class="math notranslate nohighlight" id="equation-eq-modellfunktion">
<span class="eqno">(1.16)<a class="headerlink" href="#equation-eq-modellfunktion" title="Permalink to this equation">#</a></span>\[F(x_k + p) \ \approx \ F(x_k) + \langle p, \nabla F(x_k) \rangle + \frac{1}{2} \langle p, \nabla^2F(x_k)p \rangle \ \eqqcolon \ m_k(p).\]</div>
<p>Unter gewissen Bedingungen an die Hessematrix <span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span>, lässt
sich ein eindeutiges Minimum der Modellfunktion <span class="math notranslate nohighlight">\(m_k(p)\)</span> in
<a class="reference internal" href="#equation-eq-modellfunktion">(1.16)</a> bestimmen, wie folgendes Theorem besagt.</p>
<div class="proof theorem admonition" id="theorem-9">
<p class="admonition-title"><span class="caption-number">Theorem 1.5 </span> (Newton-Abstiegsrichtung)</p>
<section class="theorem-content" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(\Omega \subset \R^n\)</span> ein offenes, zusammenhängendes Gebiet. Sei
außerdem <span class="math notranslate nohighlight">\(F \colon \Omega \rightarrow \R\)</span> eine in einer lokalen Umgebung
eines Punktes <span class="math notranslate nohighlight">\(x_k \in \Omega\)</span> zweimal stetig differenzierbare
Zielfunktion, deren Hessematrix <span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span> im Punkt <span class="math notranslate nohighlight">\(x_k\)</span> positiv
definit ist.</p>
<p>Dann ist der <strong>Newton-Abstiegsrichtung</strong> benannte Vektor
<span class="math notranslate nohighlight">\(p_k^N \in \R^n\)</span> mit</p>
<div class="math notranslate nohighlight" id="equation-eq-newton-richtung">
<span class="eqno">(1.17)<a class="headerlink" href="#equation-eq-newton-richtung" title="Permalink to this equation">#</a></span>\[p_k^N \ = \ -(\nabla^2 F(x_k))^{-1} \nabla F(x_k)\]</div>
<p>das eindeutige Minimum der Modellfunktion <span class="math notranslate nohighlight">\(m_k(p)\)</span> in
<a class="reference internal" href="#equation-eq-modellfunktion">(1.16)</a>.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. In den Übungsaufgaben zu zeigen. ◻</p>
</div>
<p>Mit der Newton-Abstiegsrichtung in <a class="reference internal" href="#equation-eq-newton-richtung">(1.17)</a> lässt sich
ein iteratives Abstiegsverfahren für einen initialen Punkt
<span class="math notranslate nohighlight">\(x_0 \in \Omega\)</span>, welcher geeignet in der Nähe des stationären Punktes
<span class="math notranslate nohighlight">\(x^* \in \Omega\)</span> gewählt wird, wie folgt konstruieren:</p>
<div class="math notranslate nohighlight" id="equation-eq-newton-abstieg">
<span class="eqno">(1.18)<a class="headerlink" href="#equation-eq-newton-abstieg" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k + p_k^N \ = \ x_k - (\nabla^2 F(x_k))^{-1} \nabla F(x_k).\]</div>
<p>Damit das Newton-Abstiegsverfahren in <a class="reference internal" href="#equation-eq-newton-abstieg">(1.18)</a> überhaupt
sinnvoll ist, müssen wir fordern, dass die Hessematrix in jedem Punkt
<span class="math notranslate nohighlight">\(x_k \in \Omega\)</span> der Iterationsfolge <em>regulär</em> und somit invertierbar
ist. Um sicher zu gehen, dass es sich tatsächlich um eine
Abstiegsrichtung handelt müssen wir fordern, dass die Hessematrix
<span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span> nicht nur invertierbar für alle <span class="math notranslate nohighlight">\(x_k \in \Omega\)</span> der
Iterationsfolge ist, sondern auch <em>positiv definit</em> in jedem Punkt <span class="math notranslate nohighlight">\(x_k\)</span>
ist. Denn dann ergibt eine Taylorapproximation zweiter Ordnung die
folgende Abschätzung:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
F(x_{k+1}) \ &amp;= \ F(x_k + p_k^N) \ \approx \ F(x_k) + \langle p_k^N, \nabla F(x_k) \rangle + \frac{1}{2} \langle p_k^N, \nabla^2F(x_k) p_k^N \rangle \\
\ &amp;= \ F(x_k) - \langle p_k^N, \nabla^2 F(x_k) p_k^N \rangle + \frac{1}{2} \langle p_k^N, \nabla^2F(x_k) p_k^N \rangle \\
\ &amp;= \ F(x_k) - \frac{1}{2} \underbrace{\langle p_k^N, \nabla^2 F(x_k) p_k^N}_{&gt;~0} \rangle.
\end{split}\end{split}\]</div>
<p>Wir sehen also, dass wir einen echten Abstieg der Funktionswerte
erhalten, wenn die Hessematrix <span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span> positiv definit ist für
alle <span class="math notranslate nohighlight">\(x_k \in \Omega\)</span> der Iterationsfolge. Sollte die Hessematrix nicht
positiv definit in einem Punkt <span class="math notranslate nohighlight">\(x_k\)</span> der Iterationsfolge sein, so muss
zumindest eine Abnahme der Funktionswerte vorliegen, d.h., es muss für
die Newton-Abstiegsrichtung gelten:</p>
<div class="math notranslate nohighlight">
\[\langle (\nabla^2F(x_k))^{-1} \nabla F(x_k), \nabla F(x_k) \rangle \ &gt; \ 0.\]</div>
<p>Sollte dies nicht der Fall sein, so existieren Methoden um dennoch einen
Abstieg zu erzwingen, siehe zum Beispiel <span id="id4">[<a class="reference internal" href="../../references.html#id2" title="Jorge Nocedal and Stephen J. Wright. Numerical Optimization. Springer Verlag, New York, 1 edition, 1999.">NW99</a>]</span>. Auf
diese werden wir jedoch im weiteren Verlauf der Vorlesung nicht näher
eingehen.</p>
<div class="proof remark admonition" id="remark-10">
<p class="admonition-title"><span class="caption-number">Remark 1.9 </span> (Schrittweite und Konvergenz)</p>
<section class="remark-content" id="proof-content">
<p>Das Newton-Abstiegsverfahren in <a class="reference internal" href="#equation-eq-newton-abstieg">(1.18)</a> ist ein
Abstiegsverfahren der Art <a class="reference internal" href="#equation-eq-abstiegsverfahren">(1.3)</a> dessen Schrittweite
<span class="math notranslate nohighlight">\(\alpha_k &gt; 0\)</span> implizit durch die lokale Krümmung und die Ableitung der
Funktion <span class="math notranslate nohighlight">\(F\)</span> bestimmt ist. In diesem Fall können wir <span class="math notranslate nohighlight">\(\alpha_k \equiv 1\)</span>
für alle <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span> setzen. Das Newton-Abstiegsverfahren
konvergiert in der Regel <em>quadratisch</em> gegen einen stationären Punkt
<span class="math notranslate nohighlight">\(x^* \in \Omega\)</span> mit <span class="math notranslate nohighlight">\(\nabla F(x^*)=0\)</span>, d.h. man erreicht sehr schnell
eine hohe Genauigkeit bei der Approximation von <span class="math notranslate nohighlight">\(x^*\)</span>.</p>
</section>
</div></section>
<section id="quasi-newton-verfahren">
<span id="ss-quasi-newton"></span><h2><span class="section-number">1.2.5. </span>Quasi-Newton Verfahren<a class="headerlink" href="#quasi-newton-verfahren" title="Permalink to this heading">#</a></h2>
<p>Im <a class="reference internal" href="#ss-newton"><span class="std std-ref">Newton Verfahren</span></a> haben wir das Newton Verfahren zur iterativen
Approximation eines stationären Punktes <span class="math notranslate nohighlight">\(x^* \in \Omega\)</span> einer Funktion
<span class="math notranslate nohighlight">\(F\)</span> mit <span class="math notranslate nohighlight">\(\nabla F(x^*) = 0\)</span> hergeleitet. Hierbei haben wir im Gegensatz
zu den vorherigen numerischen Verfahren auch Ableitungen höherer Ordnung
hinzugezogen. Dies führt in der Regel zu einem verbesserten
Konvergenzverhalten im Vergleich zu den Verfahren, die nur die lokale
Ableitung <span class="math notranslate nohighlight">\(\nabla F\)</span> der Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> verwenden.</p>
<p>Dennoch ist das Newton Verfahren aus numerischer Sicht noch nicht ideal,
da es einige Probleme mit sich bringt. Zuerst mussten wir fordern, dass
die Hessematrix <span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span> in jedem Punkt des
Iterationsverfahrens positiv definit ist, da ansonsten kein Abstieg der
Funktionswerte garantiert werden kann. Zweitens muss für die Berechnung
der Newton-Richtung in <a class="reference internal" href="#equation-eq-newton-richtung">(1.17)</a> zuerst die Hessematrix
bestimmt und anschließend invertiert werden. Dies ist aus
Effizienzgründen unerwünscht, da die Inversion einer <span class="math notranslate nohighlight">\(n \times n\)</span>-Matrix
bekanntlich in <span class="math notranslate nohighlight">\(\mathcal{O}(n^3)\)</span> Rechenoperationen liegt (siehe
<span id="id5">[<a class="reference internal" href="../../references.html#id3" title="Daniel Tenbrinck and Tim Roith. Vorlesungsskript zur einführung in die numerik (ws 22/23) an der fau erlangen-nürnberg. URL: https://www.math.fau.de/wp-content/uploads/2023/05/tenbrinck_script_numerik.pdf (visited on 2023-05-23).">TR</a>]</span>. Da die Bestimmung und die Inversion der Hessematrix
in jedem Iterationsschritt passieren müssen, ist das Newton Verfahren
nur eingeschränkt empfehlenswert für die numerische Optimierung.</p>
<p>Eine naheliegende Idee ist es nun die echte Hessematrix in jedem
Iterationsschritt durch eine geeignete Matrix zu approximieren, so dass
der numerische Aufwand geringer wird, d.h., wir suchen nach einer Matrix
<span class="math notranslate nohighlight">\(B_k \in \R^{n \times n}\)</span></p>
<div class="math notranslate nohighlight" id="equation-eq-matrix-bk">
<span class="eqno">(1.19)<a class="headerlink" href="#equation-eq-matrix-bk" title="Permalink to this equation">#</a></span>\[B_k \approx \nabla^2 F(x_k).\]</div>
<p>Damit können wir die Modellfunktion <span class="math notranslate nohighlight">\(m_k(p)\)</span> in <a class="reference internal" href="#equation-eq-modellfunktion">(1.16)</a>
schreiben als:</p>
<div class="math notranslate nohighlight">
\[m_k(p) \ = \ F(x_k) + \langle p, \nabla F(x_k)\rangle + \frac{1}{2} \langle p, B_k p \rangle,\]</div>
<p>das heißt, wir approximieren die Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> im <span class="math notranslate nohighlight">\(k\)</span>-ten
Iterationsschritt entlang der Richtung <span class="math notranslate nohighlight">\(p \in \mathbb{R}^n\)</span> lokal durch
eine quadratische Funktion. Für sehr kleine Schrittweiten können wir
davon ausgehen, dass der Fehler dieser Approximation gering ist, da wir
davon ausgehen, dass <span class="math notranslate nohighlight">\(F\)</span> stetig differenzierbar in einer lokalen
Umgebung <span class="math notranslate nohighlight">\(U \subset \Omega\)</span> des stationären Punktes <span class="math notranslate nohighlight">\(x^* \in \Omega\)</span> ist
und für <span class="math notranslate nohighlight">\(p = 0\)</span> die Approximation exakt ist, da gilt</p>
<div class="math notranslate nohighlight">
\[m_k(0) \ = \ F(x_k).\]</div>
<p>Wenn wir fordern, dass <span class="math notranslate nohighlight">\(B_k\)</span> in <a class="reference internal" href="#equation-eq-matrix-bk">(1.19)</a> eine positiv definite
Matrix ist, so lässt sich ein Abstiegsschritt des Iterationsverfahrens
<a class="reference internal" href="#equation-eq-abstiegsverfahren">(1.3)</a> analog zur Herleitung des Newton
Abstiegsverfahrens in <a class="reference internal" href="#ss-newton"><span class="std std-ref">Newton Verfahren</span></a> angeben als:</p>
<div class="math notranslate nohighlight" id="equation-eq-quasi-newton-abstieg">
<span class="eqno">(1.20)<a class="headerlink" href="#equation-eq-quasi-newton-abstieg" title="Permalink to this equation">#</a></span>\[x_{k+1} \ = \ x_k + \alpha_k p_k, \qquad p_k \ = \ -B_k^{-1} \nabla F(x_k).\]</div>
<p>Die sogenannten <em>Quasi-Newton Verfahren</em> verfolgen diesen Ansatz.</p>
<div class="proof remark admonition" id="remark-11">
<p class="admonition-title"><span class="caption-number">Remark 1.10 </span> (Konvergenzgeschwindigkeit Quasi-Newton Verfahren)</p>
<section class="remark-content" id="proof-content">
<p>Durch die Approximation der echten Hessematrix verlieren Quasi-Newton
Verfahren an Genauigkeit, wodurch ihre Konvergenzgeschwindigkeit
<em>superlinear</em> anstatt <em>quadratisch</em> ist. Dafür gewinnen sie zusätzliche
Geschwindigkeit durch die Vermeidung der Bestimmung und Inversion von
<span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span>. Der Vorteil der Quasi-Newton Methoden ist es, dass
man nur den Gradienten <span class="math notranslate nohighlight">\(\nabla F\)</span> für einen Schritt des numerischen
Optimierungsverfahrens benötigt und keine expliziten Informationen über
die zweiten Ableitungen. Dadurch werden sie in bestimmten Problemen
sogar effizienter bei der Approximation eines stationären Punktes als
das Newton Abstiegsverfahren in <a class="reference internal" href="#ss-newton"><span class="std std-ref">Newton Verfahren</span></a>.</p>
</section>
</div><section id="sekantengleichung-und-krummungsbedingung">
<span id="id6"></span><h3><span class="section-number">1.2.5.1. </span>Sekantengleichung und Krümmungsbedingung<a class="headerlink" href="#sekantengleichung-und-krummungsbedingung" title="Permalink to this heading">#</a></h3>
<p>Die entscheidende Frage bei der Konstruktion eines Quasi-Newton
Abstiegsverfahrens der Form <a class="reference internal" href="#equation-eq-quasi-newton-abstieg">(1.20)</a> ist es, wie
die positiv definite Matrix <span class="math notranslate nohighlight">\(B_k\)</span> in jedem Schritt möglichst effizient
bestimmt werden kann. Anstatt die Näherung <span class="math notranslate nohighlight">\(B_k\)</span> der Hessematrix
<span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span> in jedem Schritt von Grund auf neu zu berechnen, wäre
es wünschenswert ein initiales <span class="math notranslate nohighlight">\(B_0\)</span> zu bestimmen, das in jedem Schritt
des Iterationsverfahrens nur aktualisiert werden muss. Hierbei ist es
möglich die durch den Iterationsschritt erhaltenen Informationen über
den Gradienten <span class="math notranslate nohighlight">\(\nabla F\)</span> zu Hilfe zu nehmen.</p>
<p>Wir nehmen an, wir haben bereits einen Abstiegsschritt durchgeführt und
so einen neuen Punkt <span class="math notranslate nohighlight">\(x_{k+1} = x_k + \alpha_kp\)</span> erhalten. Unsere
quadratische Approximation in diesem neuen Punkt für eine neue Richtung
<span class="math notranslate nohighlight">\(p \in \mathbb{R}^n\)</span> sieht dementsprechend wie folgt aus:</p>
<div class="math notranslate nohighlight" id="equation-eq-quasi-newton-modellfunktion">
<span class="eqno">(1.21)<a class="headerlink" href="#equation-eq-quasi-newton-modellfunktion" title="Permalink to this equation">#</a></span>\[m_{k+1}(p) \ = \ F(x_{k+1}) + \langle \nabla F(x_{k+1}), p \rangle + \frac{1}{2}\langle p, B_{k+1}p \rangle.\]</div>
<p>Es ist leicht einzusehen, dass die Modellfunktion <span class="math notranslate nohighlight">\(m_{k+1}\)</span> im Punkt
<span class="math notranslate nohighlight">\(x_{k+1} \in \R^n\)</span> zentriert ist und für <span class="math notranslate nohighlight">\(p=0\)</span> mit dem Funktionswert der
Zielfunktion im Punkt <span class="math notranslate nohighlight">\(x_{k+1}\)</span> übereinstimmt, d.h., es gilt
<span class="math notranslate nohighlight">\(m_{k+1}(0) = F(x_{k+1})\)</span>.</p>
<p>Da wir uns bei der Wahl der positiv definiten Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span> noch
nicht festgelegt haben, wird durch <a class="reference internal" href="#equation-eq-quasi-newton-modellfunktion">(1.21)</a>
eine Funktionenschar beschrieben. Eine Forderung, die man nun die
Modellfunktion <span class="math notranslate nohighlight">\(m_{k+1}\)</span> stellen kann, um eine sinnvolle Matrix
<span class="math notranslate nohighlight">\(B_{k+1}\)</span> zu bestimmen, ist, dass ihre Ableitung <span class="math notranslate nohighlight">\(\nabla m_{k+1}\)</span> mit
der Ableitung der Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> in den letzten beiden Punkten <span class="math notranslate nohighlight">\(x_k\)</span>
und <span class="math notranslate nohighlight">\(x_{k+1}\)</span> übereinstimmt. Dies bedeutet, dass man die Matrix
<span class="math notranslate nohighlight">\(B_{k+1}\)</span> versucht so zu bestimmen, dass die Modellfunktion <span class="math notranslate nohighlight">\(m_{k+1}\)</span>
die Krümmung der Zielfunktion <span class="math notranslate nohighlight">\(F\)</span> gut approximiert. Da bereits gilt</p>
<div class="math notranslate nohighlight">
\[\nabla m_{k+1}(0) \ = \ \nabla F(x_{k+1}),\]</div>
<p>ist eine der beiden Forderungen automatisch erfüllt. Für die zweite
Forderung können wir nutzen, dass <span class="math notranslate nohighlight">\(x_k = x_{k+1} - \alpha_k p_k\)</span> gilt
und wir erhalten somit:</p>
<div class="math notranslate nohighlight" id="equation-eq-quasi-newton-forderung">
<span class="eqno">(1.22)<a class="headerlink" href="#equation-eq-quasi-newton-forderung" title="Permalink to this equation">#</a></span>\[\nabla F(x_k) \ \overset{!}{=} \ \nabla m_{k+1}(-\alpha_kp_k) \ = \ \nabla F(x_{k+1}) - B_{k+1}\alpha_kp_k.\]</div>
<p>Durch Umstellen von <a class="reference internal" href="#equation-eq-quasi-newton-forderung">(1.22)</a> erhalten wir die
Bedingung</p>
<div class="math notranslate nohighlight">
\[\nabla F(x_{k+1}) - \nabla F(x_k)  \ \overset{!}{=} \ B_{k+1}\alpha_k p_k \ = \ B_{k+1}(x_{k+1} - x_k).\]</div>
<p>Eine vernünftige Wahl der Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span> in <a class="reference internal" href="#equation-eq-matrix-bk">(1.19)</a> sollte
diese Eigenschaft, auch bekannt als <strong>Sekantengleichung</strong>, versuchen zu
imitieren. Im eindimensionalen Fall mit
<span class="math notranslate nohighlight">\(F \colon \Omega \subset \mathbb{R} \rightarrow \mathbb{R}\)</span> bedeutet die
Sekantengleichung nichts anderes, als dass der Faktor <span class="math notranslate nohighlight">\(B_{k+1}\)</span> eine
Approximation des zweiten Ableitung von <span class="math notranslate nohighlight">\(F\)</span> im Sinne eines
Differenzenquotienten ist, d.h., im Fall <span class="math notranslate nohighlight">\(n=1\)</span> soll gelten:</p>
<div class="math notranslate nohighlight">
\[B_{k+1} \ \overset{!}{=} \ \frac{F'(x_{k+1})-F'(x_k)}{x_{k+1} - x_k}.\]</div>
<p>Für unser allgemeines Quasi-Newton Verfahren in
<a class="reference internal" href="#equation-eq-quasi-newton-abstieg">(1.20)</a> suchen wir also einen Weg die bereits
bekannte Approximation der Hessematrix <span class="math notranslate nohighlight">\(B_k \approx \nabla^2F(x_k)\)</span> zu
einer Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span> zu aktualisieren, so dass der folgende
Zusammenhang für den nächsten Punkt <span class="math notranslate nohighlight">\(x_{k+1} \in \Omega\)</span> erfüllt wird:</p>
<div class="math notranslate nohighlight" id="equation-eq-sekantengleichung">
<span class="eqno">(1.23)<a class="headerlink" href="#equation-eq-sekantengleichung" title="Permalink to this equation">#</a></span>\[B_{k+1} s_k \ = \ y_k,\]</div>
<p>wobei</p>
<div class="math notranslate nohighlight">
\[s_k \ = \ x_{k+1} - x_k, \qquad y_k = \nabla F(x_{k+1}) - \nabla F(x_k).\]</div>
<p>Es wird klar, dass diese Forderung alleine nicht genügt für die
Konstruktion eines Abstiegsverfahrens, da die Sekantengleichung in
<a class="reference internal" href="#equation-eq-sekantengleichung">(1.23)</a> für <span class="math notranslate nohighlight">\(n &gt; 1\)</span> unterbestimmt ist, d.h., dass es
mehr unbekannte Einträge der Matrix <span class="math notranslate nohighlight">\(B_{k+1} \in \R^{n \times n}\)</span> gibt
als durch die <span class="math notranslate nohighlight">\(n\)</span> Gleichungen festgelegt werden. Daher versuchen wir im
Folgenden weitere Forderungen an die Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span> zu stellen.</p>
<p>Um die positive Definitheit der Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span> in Schrittrichtung
<span class="math notranslate nohighlight">\(x_{k+1} - x_k = \alpha p_k \in \R^n\)</span> zu gewährleisten müssen wir
fordern, dass die Vektoren <span class="math notranslate nohighlight">\(y_k\)</span> und <span class="math notranslate nohighlight">\(s_k\)</span> die sogenannte
<strong>Krümmungsbedingung</strong> erfüllen:</p>
<div class="math notranslate nohighlight" id="equation-eq-kruemmungsbedingung">
<span class="eqno">(1.24)<a class="headerlink" href="#equation-eq-kruemmungsbedingung" title="Permalink to this equation">#</a></span>\[\langle s_k, y_k \rangle \ &gt; \ 0.\]</div>
<p>Dies ist eine hinreichende Bedingung für die positive Definitheit von
<span class="math notranslate nohighlight">\(B_{k+1}\)</span> bezüglich der Richtung <span class="math notranslate nohighlight">\(\alpha_k p_k\)</span>, da wir einfach die
Sekantengleichung <a class="reference internal" href="#equation-eq-sekantengleichung">(1.23)</a> von links mit dem Vektor
<span class="math notranslate nohighlight">\(s_k^T\)</span> multiplizieren können und so erhalten wir mit der Forderung
<a class="reference internal" href="#equation-eq-kruemmungsbedingung">(1.24)</a> schon:</p>
<div class="math notranslate nohighlight">
\[\langle s_k, B_{k+1}s_k \rangle \ = \ \langle s_k, y_k \rangle \ &gt; \ 0.\]</div>
<div class="proof remark admonition" id="remark-12">
<p class="admonition-title"><span class="caption-number">Remark 1.11 </span> (Krümmungsbedingung und Konvexität)</p>
<section class="remark-content" id="proof-content">
<p>Falls die Zielunktion <span class="math notranslate nohighlight">\(F\)</span> strikt konvex ist, so ist die
Krümmungsbedingung <a class="reference internal" href="#equation-eq-kruemmungsbedingung">(1.24)</a> für alle Punktepaare
<span class="math notranslate nohighlight">\(x_k, x_{k+1} \in \Omega\)</span> erfüllt und die Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span> wird damit
positiv definit. Für nichtkonvexe Funktionen hingegen muss man die
Krümmungsbedingung explizit forcieren, um ein Abstiegsverfahren zu
erhalten.</p>
</section>
</div><p>Falls die Krümmungsbedingung <a class="reference internal" href="#equation-eq-kruemmungsbedingung">(1.24)</a> erfüllt ist,
so existiert mindestens eine Lösung <span class="math notranslate nohighlight">\(B_{k+1}\)</span> der Sekantengleichung
<a class="reference internal" href="#equation-eq-sekantengleichung">(1.23)</a>. Man sieht ein, dass es in der Tat sogar
unendlich viele Lösungen <span class="math notranslate nohighlight">\(B_{k+1}\)</span> gibt, da eine symmetrische
<span class="math notranslate nohighlight">\(n \times n\)</span> Matrix <span class="math notranslate nohighlight">\(n(n+1)/2\)</span> Freiheitsgrade besitzt und die
Sekantengleichung <a class="reference internal" href="#equation-eq-sekantengleichung">(1.23)</a> nur <span class="math notranslate nohighlight">\(n\)</span> Bedingungen an
<span class="math notranslate nohighlight">\(B_{k+1}\)</span> stellt. Zusätzlich erhält man <span class="math notranslate nohighlight">\(n\)</span> Bedingungen an <span class="math notranslate nohighlight">\(B_{k+1}\)</span>
durch die Forderung von positiver Definitheit, da alle <span class="math notranslate nohighlight">\(n\)</span> Hauptminoren
von <span class="math notranslate nohighlight">\(B_{k+1}\)</span> positiv sein müssen. Dies reicht jedoch nicht für die
eindeutige Bestimmung der Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span>. Hierfür müssen wir
zusätzlich fordern, dass die Matrix <span class="math notranslate nohighlight">\(B_{k+1}\)</span> diejenige Matrix unter
allen möglichen Lösungen ist, die der vorherigen Matrix <span class="math notranslate nohighlight">\(B_k\)</span> am
nächsten bezüglich eines geeigneten Maßes ist. Das heißt wir suchen eine
Lösung des folgenden Optimierungsproblems:</p>
<div class="math notranslate nohighlight" id="equation-eq-quasi-newton-optimization-problem">
<span class="eqno">(1.25)<a class="headerlink" href="#equation-eq-quasi-newton-optimization-problem" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{split}
\min_{B \in \R^{n\times n}} || B - B_k ||, \quad \text{ unter den Nebenbedingungen: } \\
B \ = \ B^T, \qquad B s_k \ = \ y_k, \qquad \langle p, Bp \rangle &gt; 0, \forall p \in \mathbb{R}^n / \lbrace 0 \rbrace,
\end{split}\end{split}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(s_k\)</span> und <span class="math notranslate nohighlight">\(y_k\)</span> definiert sind wie in der Sekantengleichung
<a class="reference internal" href="#equation-eq-sekantengleichung">(1.23)</a>. Man beachte, dass man eine unterschiedliche
Lösung <span class="math notranslate nohighlight">\(B_{k+1}\)</span> des Optimierungsproblems
<a class="reference internal" href="#equation-eq-quasi-newton-optimization-problem">(1.25)</a> in Abhängigkeit der gewählten
Matrixnorm erhält und somit auch ein unterschiedliches Quasi-Newton
Verfahren herleiten kann.</p>
</section>
<section id="das-davidon-fletcher-powell-verfahren">
<span id="id7"></span><h3><span class="section-number">1.2.5.2. </span>Das Davidon-Fletcher-Powell Verfahren<a class="headerlink" href="#das-davidon-fletcher-powell-verfahren" title="Permalink to this heading">#</a></h3>
<p>Im ursprünglich im Jahr <span class="math notranslate nohighlight">\(1959\)</span> von Davidon vorgeschlagenen Verfahren
<span id="id8">[<a class="reference internal" href="../../references.html#id10">Dav59</a>]</span> (das im Übrigen bei der Erstbegutachtung
abgelehnt wurde) wählt man für die Norm im Optimierungsproblem
<a class="reference internal" href="#equation-eq-quasi-newton-optimization-problem">(1.25)</a> eine gewichtete Frobeniusnorm
der Form</p>
<div class="math notranslate nohighlight">
\[||A||_W \ \coloneqq \ || W^\frac{1}{2}A W^{-\frac{1}{2}} ||_F.\]</div>
<p>Die Gewichtungsmatrix <span class="math notranslate nohighlight">\(W\)</span> dient dazu, dass das implizierte Quasi-Newton
Verfahren zur Approximation eines stationären Punktes <span class="math notranslate nohighlight">\(x^* \in \Omega\)</span>
skalierungs-invariant wird. Hierzu wählt man eine beliebige Matrix für
die die Relation <span class="math notranslate nohighlight">\(W y_k = s_k\)</span> gilt, d.h., eine Matrix <span class="math notranslate nohighlight">\(W\)</span>, die sich wie
die Inverse der Matrix <span class="math notranslate nohighlight">\(B\)</span> in <a class="reference internal" href="#equation-eq-quasi-newton-optimization-problem">(1.25)</a>
verhält. Ein konkretes Beispiel für solch eine Gewichtungsmatrix wäre
<span class="math notranslate nohighlight">\(W \coloneqq G_k^{-1}\)</span>, wobei <span class="math notranslate nohighlight">\(G_k\)</span> die <em>durchschnittliche Hessematrix</em>
von <span class="math notranslate nohighlight">\(F\)</span> entlang des letzten Abstiegsschritts von
<span class="math notranslate nohighlight">\(x_k \rightarrow x_{k+1}\)</span> ist mit</p>
<div class="math notranslate nohighlight">
\[G_k \ \coloneqq \ \int_0^1 \nabla^2 F(x_k + t \alpha_k p_k)~\mathrm{d}t.\]</div>
<p>Mit der konkreten Wahl dieser Gewichtungsmatrix <span class="math notranslate nohighlight">\(W = G_k^{-1}\)</span> wird die
gewichtete Frobeniusnorm dimensionslos und man erhält eine eindeutige
Lösung des Optimierungsproblems
<a class="reference internal" href="#equation-eq-quasi-newton-optimization-problem">(1.25)</a> wie folgt:</p>
<div class="math notranslate nohighlight" id="equation-eq-dfp">
<span class="eqno">(1.26)<a class="headerlink" href="#equation-eq-dfp" title="Permalink to this equation">#</a></span>\[B_{k+1} \ = \ (I-\gamma_k y_ks_k^T) B_k (I - \gamma_k s_k y_k^T) + \gamma_k y_k y_k^T, \quad \text{ mit } \gamma_k \ \coloneqq \ \frac{1}{\langle y_k, s_k \rangle}.\]</div>
<p>Die Gleichung <a class="reference internal" href="#equation-eq-dfp">(1.26)</a> wird auch <strong>DFP-Schritt</strong> genannt, da sie
zuerst von Davidon vorgeschlagen und später von Fletcher und Powell
untersucht und verbreitet wurde.</p>
<p>Obwohl wir die explizite Berechnung der Hessematrix <span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span>
vermieden haben und die Aktualisierung der Matrix <span class="math notranslate nohighlight">\(B_k\)</span> zu <span class="math notranslate nohighlight">\(B_{k+1}\)</span>
lediglich auf den Gradienteninformationen von <span class="math notranslate nohighlight">\(F\)</span> basiert ist der
numerische Aufwand bei direkter Verwendung von <span class="math notranslate nohighlight">\(B_{k+1}\)</span> in <a class="reference internal" href="#equation-eq-dfp">(1.26)</a>
noch zu hoch. Das liegt daran, dass wir für einen Schritt des
Quasi-Newton Verfahrens in <a class="reference internal" href="#equation-eq-quasi-newton-abstieg">(1.20)</a> die Inverse der
Matrix <span class="math notranslate nohighlight">\(B_k\)</span> benötigen und die Inversion einen numerischen Aufwand von
<span class="math notranslate nohighlight">\(\mathcal{O}(n^3)\)</span> besitzt. Glücklicherweise gibt es einen Trick, wie
wir die Inverse von <span class="math notranslate nohighlight">\(B_k\)</span> in jedem Schritt des Iterationsverfahrens
numerisch günstig erhalten können. Sei <span class="math notranslate nohighlight">\(H_k \coloneqq B_k^{-1}\)</span>, dann
können wir die sogenannte Sherman-Morrison-Woodbury Formel (siehe
<span id="id9">[<a class="reference internal" href="../../references.html#id9" title="Wikipedia. Sherman -morrison-woodbury formel. URL: https://de.wikipedia.org/wiki/Sherman-Morrison-Woodbury-Formel (visited on 2023-05-02).">Wikb</a>]</span>) auf Gleichung <a class="reference internal" href="#equation-eq-dfp">(1.26)</a> anwenden um die neue
Inverse <span class="math notranslate nohighlight">\(H_{k+1}\)</span> durch eine Aktualisierung der Matrix <span class="math notranslate nohighlight">\(H_k\)</span> zu
berechnen:</p>
<div class="math notranslate nohighlight" id="equation-eq-smw-formel">
<span class="eqno">(1.27)<a class="headerlink" href="#equation-eq-smw-formel" title="Permalink to this equation">#</a></span>\[H_{k+1} \ = \ H_k - \frac{H_k y_k y_k^T H_k}{\langle y_k, H_k y_k\rangle} + \frac{s_k s_k^T}{\langle y_k, s_k \rangle} .\]</div>
<p>Wie man einssieht liegt der numerische Rechenaufwand für das Update von
<span class="math notranslate nohighlight">\(H_{k+1}\)</span> in <a class="reference internal" href="#equation-eq-smw-formel">(1.27)</a> in <span class="math notranslate nohighlight">\(\mathcal{O}(n^2)\)</span>. Es fällt
außerdem auf, dass <span class="math notranslate nohighlight">\(H_k\)</span> nur durch die Addition zweier Matrizen mit Rang
<span class="math notranslate nohighlight">\(1\)</span> verändert wird, also insgesamt eine Änderung von höchstes Rang <span class="math notranslate nohighlight">\(2\)</span>
erfährt. Das passt gut zu der Forderung, dass wir erwarten, dass sich
die Approximation der Hessematrix <span class="math notranslate nohighlight">\(\nabla^2 F\)</span> in einer lokalen Umgebung
nur wenig ändert.</p>
</section>
<section id="das-broyden-fletcher-goldfarb-shanno-verfahren">
<span id="das-broydenfletchergoldfarbshanno-verfahren"></span><h3><span class="section-number">1.2.5.3. </span>Das Broyden–Fletcher–Goldfarb–Shanno Verfahren<a class="headerlink" href="#das-broyden-fletcher-goldfarb-shanno-verfahren" title="Permalink to this heading">#</a></h3>
<p>Das Davidon–Fletcher–Powell Verfahren wurde trotz seiner Effektivität
bald schon durch ein Verfahren abgelöst, das noch besser war und bis
heute zu den effizientesten Quasi-Newton Verfahren gehört: das
Broyden–Fletcher–Goldfard–Shanno (BFGS) Verfahren in
<span id="id10">[<a class="reference internal" href="../../references.html#id13" title="Charles G. Broyden. The Convergence of a Class of Double-rank Minimization Algorithms 1. General Considerations. IMA Journal of Applied Mathematics, 6(1):76-90, 1970. arXiv:https://academic.oup.com/imamat/article-pdf/6/1/76/2233756/6-1-76.pdf.">Bro70</a>]</span>. Die Idee des BFGS Verfahrens leitet sich
unmittelbar aus der Idee des DFP Verfahren ab. Anstatt das
Optimierungsproblem <a class="reference internal" href="#equation-eq-quasi-newton-optimization-problem">(1.25)</a> mit
bestimmten Bedingungen an die Approximation <span class="math notranslate nohighlight">\(B_{k+1}\)</span> der Hessematrix
<span class="math notranslate nohighlight">\(\nabla^2 F(x_k)\)</span> zu stellen, versucht man direkt die Inverse der
Hessematrix <span class="math notranslate nohighlight">\((\nabla^2 F(x_k))^{-1}\)</span> geeignet zu approximieren. Hierfür
nehmen wir an, dass wir eine Matrix <span class="math notranslate nohighlight">\(H_{k+1}\)</span> als geringfügige
Aktualisierung einer bereits vorher bestimmten Matrix <span class="math notranslate nohighlight">\(H_k\)</span> suchen, die
gleichzeitig symmetrisch und positiv definit ist und zusätzlich die
Sekantenbedingung in umgeschriebener Form erfüllt:</p>
<div class="math notranslate nohighlight">
\[H_{k+1}y_k \ = \ s_k.\]</div>
<p>Hierzu formuliert man ein analoges Optimierungsproblem zu
<a class="reference internal" href="#equation-eq-quasi-newton-optimization-problem">(1.25)</a> von der Form:</p>
<div class="math notranslate nohighlight" id="equation-eq-bfgs-optimierungsproblem">
<span class="eqno">(1.28)<a class="headerlink" href="#equation-eq-bfgs-optimierungsproblem" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{split}
\min_{H} || H - H_k ||, \quad \text{ unter den Nebenbedingungen: } \\
H \ = \ H^T, \qquad H y_k \ = \ s_k, \qquad \langle p, Hp \rangle &gt; 0, \forall p \in \mathbb{R}^n / \lbrace 0 \rbrace.
\end{split}\end{split}\]</div>
<p>Unter der Verwendung der gewichteten Frobeniusnorm und einer beliebigen
Gewichtsfunktion, die die Sekantengleichung <span class="math notranslate nohighlight">\(Ws_k = y_k\)</span> erfüllt, erhält
man wiederum die eindeutige Lösung des Minimierungsproblems
<a class="reference internal" href="#equation-eq-bfgs-optimierungsproblem">(1.28)</a> als:</p>
<div class="math notranslate nohighlight" id="equation-eq-bfgs">
<span class="eqno">(1.29)<a class="headerlink" href="#equation-eq-bfgs" title="Permalink to this equation">#</a></span>\[H_{k+1} \ = \ (I - \rho_k s_k y_k^T) H_k (I - \rho_k y_k s_k^T) + \rho_k s_k s_k^T, \quad \text{ mit } \rho_k \coloneqq \frac{1}{\langle y_k, s_k \rangle}.\]</div>
<p>Das Update der Matrix <span class="math notranslate nohighlight">\(H_k\)</span> in <a class="reference internal" href="#equation-eq-bfgs">(1.29)</a> kann numerisch in
<span class="math notranslate nohighlight">\(\mathcal{O}(n^2)\)</span> durchgeführt werden, was man schnell einsieht, wenn
man das Produkt ausschreibt:</p>
<div class="math notranslate nohighlight">
\[H_{k+1} \ = \ H_k - H_k\rho_k y_k s_k^T - \rho_k s_k y_k^T H_k + \rho_k s_k y_k^T H_k \rho_k y_k s_k^T + \rho_k s_k s_k^T.\]</div>
<p>In dieser Schreibweise sieht man gut, dass man lediglich Skalarprodukte
in <span class="math notranslate nohighlight">\(\mathcal{O}(n)\)</span>, Matrix-Vektor Multiplikationen in
<span class="math notranslate nohighlight">\(\mathcal{O}(n^2)\)</span> und dyadische Produkte in <span class="math notranslate nohighlight">\(\mathcal{O}(n^2)\)</span>
berechnen muss. Im Gegensatz hierzu würde eine naive Implementierung des
BFGS-Updates in <a class="reference internal" href="#equation-eq-bfgs">(1.29)</a> zu einem numerischen Aufwand von
<span class="math notranslate nohighlight">\(\mathcal{O}(n^3)\)</span> führen.</p>
<p>Abschließend bleibt die Frage was eine gute Initialisierung der Matrix
<span class="math notranslate nohighlight">\(H_0\)</span> ist. Idealerweise hat man bereits Informationen über die Inverse
der Hessematrix <span class="math notranslate nohighlight">\((\nabla^2 F(x_0))^{-1}\)</span> im Initialisierungspunkt
<span class="math notranslate nohighlight">\(x_0 \in \Omega\)</span>, zum Beispiel durch eine numerische Approximation
mittels finiter Differenzen (später in der Vorlesung!). Andererseits
erwarten wir, dass die Aktualisierung von <span class="math notranslate nohighlight">\(H_k\)</span> im <span class="math notranslate nohighlight">\(k\)</span>-ten Schritt des
Iterationsverfahrens <a class="reference internal" href="#equation-eq-bfgs">(1.29)</a> zu <span class="math notranslate nohighlight">\(H_{k+1}\)</span> die aktuellen
Informationen über den Verlauf der Gradienten <span class="math notranslate nohighlight">\(\nabla F(x_k)\)</span> und
<span class="math notranslate nohighlight">\(\nabla F(x_{k+1})\)</span> berücksichtigt. Darum ist eine häufige Wahl von
<span class="math notranslate nohighlight">\(H_0\)</span> die Initialisierung als Einheitsmatrix <span class="math notranslate nohighlight">\(I_n\)</span> oder ein Vielfaches
der Einheitsmatrix, wobei die Vorfaktoren der Diagonaleinträge
entsprechend der Skalierung der Variablen gewählt werden.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./optimierung\02_NichtlineareOptimierung"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_02_NichtlineareOptimierung.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">zurück</p>
        <p class="prev-next-title"><span class="section-number">1.1. </span>Mathematische Grundlagen</p>
      </div>
    </a>
    <a class="right-next"
       href="03_02_NichtlineareOptimierung.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">weiter</p>
        <p class="prev-next-title"><span class="section-number">1.3. </span>Verfahren der konjugierten Gradienten</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Inhalt
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradientenabstiegsverfahren">1.2.1. Gradientenabstiegsverfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#koordinatenabstiegsverfahren">1.2.2. Koordinatenabstiegsverfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastisches-gradientenabstiegsverfahren">1.2.3. Stochastisches Gradientenabstiegsverfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren">1.2.4. Newton Verfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quasi-newton-verfahren">1.2.5. Quasi-Newton Verfahren</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sekantengleichung-und-krummungsbedingung">1.2.5.1. Sekantengleichung und Krümmungsbedingung</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-davidon-fletcher-powell-verfahren">1.2.5.2. Das Davidon-Fletcher-Powell Verfahren</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-broyden-fletcher-goldfarb-shanno-verfahren">1.2.5.3. Das Broyden–Fletcher–Goldfarb–Shanno Verfahren</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Durch J. Laubmann, T. Roith, D. Tenbrinck
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2021.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <script type="application/json" class="js-hypothesis-config">{"assetRoot": "http://hypothesis.fau-mads.eu:3001/hypothesis/1.0.0-dummy-version/", "sidebarAppUrl":"http://hypothesis.fau-mads.eu:5000/app.html"}</script>
<script async="async" kind="hypothesis" src="http://hypothesis.fau-mads.eu:5000/embed.js"></script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>